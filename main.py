import os
import json 
from openai import OpenAI
from db.neo4j_handler import Neo4jHandler
from core.bridge import process_and_learn, attempt_innovative_solution
from core.verify_causal import verify_causal_path
import httpx 
from dotenv import load_dotenv

# Load variables from .env file
load_dotenv()

# ----------------------------------------------------------------------
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙ‡ÙŠØ¦Ø© (Configuration)
# ----------------------------------------------------------------------

# âš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: ÙŠØ¬Ø¨ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙŠÙ…
# NEO4J_URI = os.getenv("NEO4J_URI", "neo4j://127.0.0.1:7687")
NEO4J_URI = os.getenv("NEO4J_URI")
# NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
NEO4J_USER = os.getenv("NEO4J_USER")
# NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "123456Aa@")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
# OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "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")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ (Ù…Ø¹ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ¬Ø§ÙˆØ² Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ÙˆÙƒÙŠÙ„/TypeError)
try:
    http_client = httpx.Client()
    llm_client = OpenAI(api_key=OPENAI_API_KEY, http_client=http_client)

except TypeError:
    print("ØªØ­Ø°ÙŠØ±: ÙØ´Ù„Øª Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ© Ù„Ù„Ø¹Ù…ÙŠÙ„ØŒ Ø§Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©.")
    llm_client = OpenAI(api_key=OPENAI_API_KEY)

# ØªÙ‡ÙŠØ¦Ø© Ù…ÙØ¹Ø§Ù„Ø¬ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
neo4j_handler = Neo4jHandler(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)

# ----------------------------------------------------------------------
# 2. ÙˆØ¸ÙŠÙØ© Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙØ±Ø¶ÙŠØ© (Ù„Ù„ØªØ´ØºÙŠÙ„ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø«Ø§Ù„)
# ----------------------------------------------------------------------

def mock_extract_claims(scenario: str) -> str:
    """Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙØ±Ø¶ÙŠØ© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ© ÙƒÙ€ JSON (Ù„ØªØ¬Ù†Ø¨ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ LLM Ø­Ù‚ÙŠÙ‚ÙŠ)."""
    if "slow database" in scenario:
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ù…Ø³Ø§Ø± Ù†Ø§Ø¬Ø­ ÙˆÙ…ÙˆØ«ÙˆÙ‚
        return json.dumps({
            "causal_claims": [
                {"cause": "Database Query Slowdown", "effect": "High Latency"}
            ]
        })
    elif "CPU usage" in scenario:
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: Ù…Ø³Ø§Ø± ØºÙŠØ± Ù…ÙˆØ«ÙˆÙ‚ Ø£Ùˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯
        return json.dumps({
            "causal_claims": [
                {"cause": "increase thread priority", "effect": "better performance"}
            ]
        })
    return json.dumps({"causal_claims": []})

# ----------------------------------------------------------------------
# 3. Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„Ø©
# ----------------------------------------------------------------------

def run_scenario_1_success_and_learn():
    """Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ø§Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ØŒ Ø«Ù… Ø§Ù„ØªØ¹Ù„Ù… Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø«Ù‚Ø©."""
    print("==================================================")
    print("ğŸ§ª Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø«Ù‚Ø©")
    print("==================================================")
    
    llm_output = mock_extract_claims("slow database") 
    
    # 2. Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„ØªØ¹Ù„Ù…).
    result = process_and_learn(llm_output, neo4j_handler, llm_client, feedback_delta=1.0) 
    
    print(f"\nâœ… Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
    print(f"Ø§Ù„Ø­Ø§Ù„Ø©: {result['status']}")
    
    if 'message' in result:
        print(f"Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {result['message']}")
    elif 'question' in result:
        print(f"Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {result['question']}")

    if 'system_confidence' in result:
        print(f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯: {result['system_confidence']}")
    

def run_scenario_2_failure_and_active_learning():
    """Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: Ø§Ù„ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ØŒ ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù†Ø´Ø·ØŒ ÙˆØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø©."""
    print("\n==================================================")
    print("ğŸ§  Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù†Ø´Ø·")
    print("==================================================")
    
    llm_output = mock_extract_claims("CPU usage")
    
    result = process_and_learn(llm_output, neo4j_handler, llm_client, feedback_delta=0.0)
    
    print(f"\nâŒ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
    print(f"Ø§Ù„Ø­Ø§Ù„Ø©: {result['status']}")
    
    if 'message' in result:
        print(f"Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {result['message']}")
    elif 'question' in result:
        print(f"Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§ÙÙŠ: {result['question']}")
        
    if result['status'] == "Failure - Causal Gap Found (Active Learning)":
        if 'action_required' in result:
             print(f"Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {result['action_required']}")
    
    if 'system_confidence' in result:
        print(f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯: {result['system_confidence']}")


def run_scenario_3_innovation_and_risk_awareness():
    """Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 3: Ø§Ù„Ù„Ø¬ÙˆØ¡ Ø¥Ù„Ù‰ Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø± ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±."""
    print("\n==================================================")
    print("ğŸš€ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 3: Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø± Ø§Ù„ÙˆØ§Ø¹ÙŠ Ø¨Ø§Ù„Ù…Ø®Ø§Ø·Ø±")
    print("==================================================")
    
    cause = "High Latency"
    effect = "User Frustration"
    
    result = attempt_innovative_solution(neo4j_handler, llm_client, cause, effect)
    
    print(f"\nğŸ› ï¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø±:")
    print(f"Ø§Ù„Ø­Ø§Ù„Ø©: {result['status']}")
    if result['status'] == "Innovative Solution Found":
        print(f"Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù‚ØªØ±Ø­: {result['path']}")
        print(f"ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø± (Score): {result['risk_assessment']['risk_score']}")
        print(f"Ø§Ù„Ø¢Ø«Ø§Ø± Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©: {result['risk_assessment']['side_effects']}")
    elif result['status'] == "Innovative Solution REJECTED":
        print(f"Ø³Ø¨Ø¨ Ø§Ù„Ø±ÙØ¶: {result['message']}")
        print(f"ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±: {result['risk_details']}")
    
    
if __name__ == "__main__":
    
    # âš ï¸ Ù‡Ø§Ù…: ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ù…Ù„Ù 'data/seed_knowledge.cypher' ÙÙŠ Neo4j Ù‚Ø¨Ù„ Ø§Ù„ØªÙ†ÙÙŠØ°
    print("--- Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ OpenCausal (Ù…Ø¹ Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø°Ø§ØªÙŠ) ---")
    
    try:
        run_scenario_1_success_and_learn()
        run_scenario_2_failure_and_active_learning()
        run_scenario_3_innovation_and_risk_awareness()
        
    except Exception as e:
        print(f"\nâš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ø§Ù… (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… ØªÙ‡ÙŠØ¦Ø© Neo4jHandler Ø£Ùˆ Ù…ÙØªØ§Ø­ OpenAI): {e}")
    finally:
        print("\n--- Ø§ÙƒØªÙ…Ù„Øª Ø¯ÙˆØ±Ø§Øª OpenCausal ---")





# import os
# import json 
# from openai import OpenAI
# from db.neo4j_handler import Neo4jHandler
# from core.bridge import process_and_learn, attempt_innovative_solution
# from core.verify_causal import verify_causal_path
# import httpx 
# from dotenv import load_dotenv

# # Load variables from .env file
# load_dotenv()

# # ----------------------------------------------------------------------
# # 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙ‡ÙŠØ¦Ø© (Configuration)
# # ----------------------------------------------------------------------

# # âš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: ÙŠØ¬Ø¨ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙŠÙ…
# # NEO4J_URI = os.getenv("NEO4J_URI", "neo4j://127.0.0.1:7687")
# NEO4J_URI = os.getenv("NEO4J_URI")
# # NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
# NEO4J_USER = os.getenv("NEO4J_USER")
# # NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "123456Aa@")
# NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
# # OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "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")
# OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ (Ù…Ø¹ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ¬Ø§ÙˆØ² Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ÙˆÙƒÙŠÙ„/TypeError)
# try:
#     http_client = httpx.Client()
#     llm_client = OpenAI(api_key=OPENAI_API_KEY, http_client=http_client)

# except TypeError:
#     print("ØªØ­Ø°ÙŠØ±: ÙØ´Ù„Øª Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ© Ù„Ù„Ø¹Ù…ÙŠÙ„ØŒ Ø§Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©.")
#     llm_client = OpenAI(api_key=OPENAI_API_KEY)

# # ØªÙ‡ÙŠØ¦Ø© Ù…ÙØ¹Ø§Ù„Ø¬ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# neo4j_handler = Neo4jHandler(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)

# # ----------------------------------------------------------------------
# # 2. ÙˆØ¸ÙŠÙØ© Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙØ±Ø¶ÙŠØ© (Ù„Ù„ØªØ´ØºÙŠÙ„ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø«Ø§Ù„)
# # ----------------------------------------------------------------------

# def mock_extract_claims(scenario: str) -> str:
#     """Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙØ±Ø¶ÙŠØ© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ© ÙƒÙ€ JSON (Ù„ØªØ¬Ù†Ø¨ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ LLM Ø­Ù‚ÙŠÙ‚ÙŠ)."""
#     if "slow database" in scenario:
#         # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ù…Ø³Ø§Ø± Ù†Ø§Ø¬Ø­ ÙˆÙ…ÙˆØ«ÙˆÙ‚ (ÙÙŠ Ø§Ù„Ø¹Ø§Ø¯Ø©)
#         return json.dumps({
#             "causal_claims": [
#                 {"cause": "Database Query Slowdown", "effect": "High Latency"}
#             ]
#         })
#     elif "CPU usage" in scenario:
#         # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: Ù…Ø³Ø§Ø± ØºÙŠØ± Ù…ÙˆØ«ÙˆÙ‚ Ø£Ùˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯
#         return json.dumps({
#             "causal_claims": [
#                 {"cause": "increase thread priority", "effect": "better performance"}
#             ]
#         })
#     return json.dumps({"causal_claims": []})

# # ----------------------------------------------------------------------
# # 3. Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„Ø©
# # ----------------------------------------------------------------------

# def run_scenario_1_success_and_learn():
#     """Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ø§Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ØŒ Ø«Ù… Ø§Ù„ØªØ¹Ù„Ù… Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø«Ù‚Ø©."""
#     print("==================================================")
#     print("ğŸ§ª Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø«Ù‚Ø©")
#     print("==================================================")
#     # 1. Ù…Ø­Ø§ÙƒØ§Ø© Ø®Ø±Ø¬ LLM
#     llm_output = mock_extract_claims("slow database") 
    
#     # â­â­ ÙƒÙˆØ¯ Ø§Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… 'execute_query' â­â­
#     try:
#         neo4j_handler.execute_query("""
#             MATCH (s:State {name: 'Database Query Slowdown'}), (t:State {name: 'High Latency'})
#             MERGE (s)-[r:CAUSES]->(t)
#             SET r.weight = 0.98
#         """)
#         print(">> ØªÙ… ÙØ±Ø¶ ÙˆØ²Ù† Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¹Ù„Ù‰ 0.98 Ù„Ø¶Ù…Ø§Ù† Ù†Ø¬Ø§Ø­ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1")
#     except Exception as e:
#         # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ Ù‡Ùˆ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ 'execute_query'ØŒ ÙÙŠØ¬Ø¨ ÙØ­Øµ Neo4jHandler
#         print(f">> ÙØ´Ù„ ÙØ±Ø¶ Ø§Ù„ÙˆØ²Ù† (ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ execute_query ÙÙŠ Neo4jHandler): {e}")
#     # â­â­ Ù†Ù‡Ø§ÙŠØ© ÙƒÙˆØ¯ Ø§Ù„Ø¶Ù…Ø§Ù† â­â­

#     # 2. Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„ØªØ¹Ù„Ù…).
#     result = process_and_learn(llm_output, neo4j_handler, llm_client, feedback_delta=1.0) 
    
#     print(f"\nâœ… Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
#     print(f"Ø§Ù„Ø­Ø§Ù„Ø©: {result['status']}")
    
#     # â­â­ ØªØµØ­ÙŠØ­ Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© (Ù…Ø±ÙˆÙ†Ø© Ù„Ù‚Ø±Ø§Ø¡Ø© 'message' Ø£Ùˆ 'question') â­â­
#     if 'message' in result:
#         print(f"Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {result['message']}")
#     elif 'question' in result:
#         print(f"Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {result['question']}")

#     if 'system_confidence' in result:
#         print(f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯: {result['system_confidence']}")
    

# def run_scenario_2_failure_and_active_learning():
#     """Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: Ø§Ù„ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ØŒ ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù†Ø´Ø·ØŒ ÙˆØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø©."""
#     print("\n==================================================")
#     print("ğŸ§  Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù†Ø´Ø·")
#     print("==================================================")
    
#     llm_output = mock_extract_claims("CPU usage")
    
#     result = process_and_learn(llm_output, neo4j_handler, llm_client, feedback_delta=0.0)
    
#     print(f"\nâŒ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
#     print(f"Ø§Ù„Ø­Ø§Ù„Ø©: {result['status']}")
    
#     # â­â­ ØªØµØ­ÙŠØ­ Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© (Ù…Ø±ÙˆÙ†Ø© Ù„Ù‚Ø±Ø§Ø¡Ø© 'message' Ø£Ùˆ 'question') â­â­
#     if 'message' in result:
#         print(f"Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {result['message']}")
#     elif 'question' in result:
#         print(f"Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§ÙÙŠ: {result['question']}")
        
#     if result['status'] == "Failure - Causal Gap Found (Active Learning)":
#         if 'action_required' in result:
#              print(f"Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {result['action_required']}")
    
#     if 'system_confidence' in result:
#         print(f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯: {result['system_confidence']}")


# def run_scenario_3_innovation_and_risk_awareness():
#     """Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 3: Ø§Ù„Ù„Ø¬ÙˆØ¡ Ø¥Ù„Ù‰ Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø± ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±."""
#     print("\n==================================================")
#     print("ğŸš€ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 3: Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø± Ø§Ù„ÙˆØ§Ø¹ÙŠ Ø¨Ø§Ù„Ù…Ø®Ø§Ø·Ø±")
#     print("==================================================")
    
#     cause = "High Latency"
#     effect = "User Frustration"
    
#     result = attempt_innovative_solution(neo4j_handler, llm_client, cause, effect)
    
#     print(f"\nğŸ› ï¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø±:")
#     print(f"Ø§Ù„Ø­Ø§Ù„Ø©: {result['status']}")
#     if result['status'] == "Innovative Solution Found":
#         print(f"Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù‚ØªØ±Ø­: {result['path']}")
#         print(f"ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø± (Score): {result['risk_assessment']['risk_score']}")
#         print(f"Ø§Ù„Ø¢Ø«Ø§Ø± Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©: {result['risk_assessment']['side_effects']}")
#     elif result['status'] == "Innovative Solution REJECTED":
#         print(f"Ø³Ø¨Ø¨ Ø§Ù„Ø±ÙØ¶: {result['message']}")
#         print(f"ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±: {result['risk_details']}")
    
    
# if __name__ == "__main__":
    
#     # âš ï¸ Ù‡Ø§Ù…: ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ù…Ù„Ù 'data/seed_knowledge.cypher' ÙÙŠ Neo4j Ù‚Ø¨Ù„ Ø§Ù„ØªÙ†ÙÙŠØ°
#     print("--- Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ OpenCausal (Ù…Ø¹ Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø°Ø§ØªÙŠ) ---")
    
#     try:
#         run_scenario_1_success_and_learn()
#         run_scenario_2_failure_and_active_learning()
#         run_scenario_3_innovation_and_risk_awareness()
        
#     except Exception as e:
#         print(f"\nâš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ø§Ù… (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… ØªÙ‡ÙŠØ¦Ø© Neo4jHandler Ø£Ùˆ Ù…ÙØªØ§Ø­ OpenAI): {e}")
#     finally:
#         print("\n--- Ø§ÙƒØªÙ…Ù„Øª Ø¯ÙˆØ±Ø§Øª OpenCausal ---")






# import os
# import json 
# from openai import OpenAI
# from db.neo4j_handler import Neo4jHandler
# from core.bridge import process_and_learn, attempt_innovative_solution
# from core.verify_causal import verify_causal_path
# import httpx 
# from dotenv import load_dotenv

# # Load variables from .env file
# load_dotenv()

# # ----------------------------------------------------------------------
# # 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙ‡ÙŠØ¦Ø© (Configuration)
# # ----------------------------------------------------------------------

# # âš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: ÙŠØ¬Ø¨ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙŠÙ…
# NEO4J_URI = os.getenv("NEO4J_URI", "neo4j://127.0.0.1:7687")
# NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
# NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "123456Aa@")
# # ÙŠÙÙØªØ±Ø¶ Ø£Ù† Ù…ÙØªØ§Ø­ API ØµØ­ÙŠØ­ ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙØ¹Ù„ÙŠØ©
# # OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "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")
# OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ (Ù…Ø¹ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ¬Ø§ÙˆØ² Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ÙˆÙƒÙŠÙ„/TypeError)
# try:
#     http_client = httpx.Client()
#     llm_client = OpenAI(api_key=OPENAI_API_KEY, http_client=http_client)

# except TypeError:
#     print("ØªØ­Ø°ÙŠØ±: ÙØ´Ù„Øª Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ© Ù„Ù„Ø¹Ù…ÙŠÙ„ØŒ Ø§Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©.")
#     llm_client = OpenAI(api_key=OPENAI_API_KEY)

# # ØªÙ‡ÙŠØ¦Ø© Ù…ÙØ¹Ø§Ù„Ø¬ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# neo4j_handler = Neo4jHandler(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)

# # ----------------------------------------------------------------------
# # 2. ÙˆØ¸ÙŠÙØ© Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙØ±Ø¶ÙŠØ© (Ù„Ù„ØªØ´ØºÙŠÙ„ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø«Ø§Ù„)
# # ----------------------------------------------------------------------

# def mock_extract_claims(scenario: str) -> str:
#     """Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙØ±Ø¶ÙŠØ© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ© ÙƒÙ€ JSON (Ù„ØªØ¬Ù†Ø¨ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ LLM Ø­Ù‚ÙŠÙ‚ÙŠ)."""
#     if "slow database" in scenario:
#         # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ù…Ø³Ø§Ø± Ù†Ø§Ø¬Ø­ ÙˆÙ…ÙˆØ«ÙˆÙ‚ (ÙÙŠ Ø§Ù„Ø¹Ø§Ø¯Ø©)
#         return json.dumps({
#             "causal_claims": [
#                 {"cause": "Database Query Slowdown", "effect": "High Latency"}
#             ]
#         })
#     elif "CPU usage" in scenario:
#         # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: Ù…Ø³Ø§Ø± ØºÙŠØ± Ù…ÙˆØ«ÙˆÙ‚ Ø£Ùˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯
#         return json.dumps({
#             "causal_claims": [
#                 {"cause": "increase thread priority", "effect": "better performance"}
#             ]
#         })
#     return json.dumps({"causal_claims": []})

# # ----------------------------------------------------------------------
# # 3. Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„Ø©
# # ----------------------------------------------------------------------

# def run_scenario_1_success_and_learn():
#     """Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ø§Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ØŒ Ø«Ù… Ø§Ù„ØªØ¹Ù„Ù… Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø«Ù‚Ø©."""
#     print("==================================================")
#     print("ğŸ§ª Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø«Ù‚Ø©")
#     print("==================================================")
    
#     llm_output = mock_extract_claims("slow database") 
    
#     # 2. Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„ØªØ¹Ù„Ù…).
#     result = process_and_learn(llm_output, neo4j_handler, llm_client, feedback_delta=1.0) 
    
#     print(f"\nâœ… Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
#     print(f"Ø§Ù„Ø­Ø§Ù„Ø©: {result['status']}")
    
#     # â­â­ ØªØµØ­ÙŠØ­ Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© (Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ 'meessage' ÙˆÙ„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù…ÙØªØ§Ø­ 'question') â­â­
#     if 'message' in result:
#         print(f"Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {result['message']}")
#     elif 'question' in result:
#         print(f"Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {result['question']}")

#     if 'system_confidence' in result:
#         print(f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯: {result['system_confidence']}")
    

# def run_scenario_2_failure_and_active_learning():
#     """Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: Ø§Ù„ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ØŒ ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù†Ø´Ø·ØŒ ÙˆØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø©."""
#     print("\n==================================================")
#     print("ğŸ§  Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù†Ø´Ø·")
#     print("==================================================")
    
#     llm_output = mock_extract_claims("CPU usage")
    
#     result = process_and_learn(llm_output, neo4j_handler, llm_client, feedback_delta=0.0)
    
#     print(f"\nâŒ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
#     print(f"Ø§Ù„Ø­Ø§Ù„Ø©: {result['status']}")
    
#     # â­â­ ØªØµØ­ÙŠØ­ Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© (Ù„Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2) â­â­
#     if 'message' in result:
#         print(f"Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {result['message']}")
#     elif 'question' in result:
#         print(f"Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§ÙÙŠ: {result['question']}")
        
#     if result['status'] == "Failure - Causal Gap Found (Active Learning)":
#         if 'action_required' in result:
#              print(f"Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {result['action_required']}")
    
#     if 'system_confidence' in result:
#         print(f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯: {result['system_confidence']}")


# def run_scenario_3_innovation_and_risk_awareness():
#     """Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 3: Ø§Ù„Ù„Ø¬ÙˆØ¡ Ø¥Ù„Ù‰ Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø± ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±."""
#     print("\n==================================================")
#     print("ğŸš€ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 3: Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø± Ø§Ù„ÙˆØ§Ø¹ÙŠ Ø¨Ø§Ù„Ù…Ø®Ø§Ø·Ø±")
#     print("==================================================")
    
#     cause = "High Latency"
#     effect = "User Frustration"
    
#     result = attempt_innovative_solution(neo4j_handler, llm_client, cause, effect)
    
#     print(f"\nğŸ› ï¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø±:")
#     print(f"Ø§Ù„Ø­Ø§Ù„Ø©: {result['status']}")
#     if result['status'] == "Innovative Solution Found":
#         print(f"Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù‚ØªØ±Ø­: {result['path']}")
#         print(f"ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø± (Score): {result['risk_assessment']['risk_score']}")
#         print(f"Ø§Ù„Ø¢Ø«Ø§Ø± Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©: {result['risk_assessment']['side_effects']}")
#     elif result['status'] == "Innovative Solution REJECTED":
#         print(f"Ø³Ø¨Ø¨ Ø§Ù„Ø±ÙØ¶: {result['message']}")
#         print(f"ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±: {result['risk_details']}")
    
    
# if __name__ == "__main__":
    
#     # âš ï¸ Ù‡Ø§Ù…: ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ù…Ù„Ù 'data/seed_knowledge.cypher' ÙÙŠ Neo4j Ù‚Ø¨Ù„ Ø§Ù„ØªÙ†ÙÙŠØ°
#     print("--- Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ OpenCausal (Ù…Ø¹ Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø°Ø§ØªÙŠ) ---")
    
#     try:
#         run_scenario_1_success_and_learn()
#         run_scenario_2_failure_and_active_learning()
#         run_scenario_3_innovation_and_risk_awareness()
        
#     except Exception as e:
#         print(f"\nâš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ø§Ù… (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… ØªÙ‡ÙŠØ¦Ø© Neo4jHandler Ø£Ùˆ Ù…ÙØªØ§Ø­ OpenAI): {e}")
#     finally:
#         print("\n--- Ø§ÙƒØªÙ…Ù„Øª Ø¯ÙˆØ±Ø§Øª OpenCausal ---")
